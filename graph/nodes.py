import logging
from langchain.schema import HumanMessage, AIMessage
from langchain.prompts import ChatPromptTemplate
from db.models import save_chat_message

logger = logging.getLogger(__name__)

def profile_node(state):
    """Ú¯Ø±Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±"""
    # Ø§Ú¯Ø± Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø± Ù†Ø§Ù…Ø´Ø®Øµ Ø¨Ø§Ø´Ø¯ØŒ ÛŒÚ© Ø®Ø·Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯
    if not state["user_profile"]:
        state["response"] = "Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø®ÙˆØ¯ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯."
        return state
    
    # Ø§Ú¯Ø± Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ù…Ù„ Ù†Ø¨Ø§Ø´Ø¯ØŒ ÛŒÚ© Ø®Ø·Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯
    if not state["user_profile"].get("complete", False):
        state["response"] = "Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø´Ù…Ø§ Ù†Ø§Ù‚Øµ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ø¢Ù† Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯."
        return state
    
    # Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø§Ø³ØªØŒ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
    return state

def router_node(state):
    """Ú¯Ø±Ù‡ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ùˆ Ù…Ø³ÛŒØ±ÛŒØ§Ø¨ÛŒ"""
    # Ù†ÙˆØ¹ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø§Ø² Ù‚Ø¨Ù„ ØªØ¹ÛŒÛŒÙ† Ø´Ø¯Ù‡ Ø§Ø³Øª (Ø¯Ø± process_with_langgraph)
    return state

def study_plan_node(llm):
    """Ú¯Ø±Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÛŒ"""
    def generate_study_plan(state):
        user_profile = state["user_profile"]
        message = state["messages"][-1].content if state["messages"] else ""
        
        # Ø³Ø§Ø®Øª Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ø±Ø§ÛŒ LLM
        template = """
        Ø´Ù…Ø§ Ù…Ø´Ø§ÙˆØ± ØªØ­ØµÛŒÙ„ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ² Ù‡Ø³ØªÛŒØ¯ Ùˆ Ø¨Ø§ÛŒØ¯ ÛŒÚ© Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÛŒ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯.
        
        Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²:
        - Ù†Ø§Ù…: {name}
        - Ù¾Ø§ÛŒÙ‡ ØªØ­ØµÛŒÙ„ÛŒ: {grade}
        - ØªØ§Ø±ÛŒØ® Ú©Ù†Ú©ÙˆØ±: {exam_date}
        - Ø¯Ø±ÙˆØ³ Ù…ÙˆØ±Ø¯ Ø¹Ù„Ø§Ù‚Ù‡: {favorite_subjects}
        - Ø¯Ø±ÙˆØ³ Ù…ÙˆØ±Ø¯ Ù†ÙØ±Øª: {disliked_subjects}
        - Ø±Ø´ØªÙ‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±: {desired_major}
        
        Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²: {message}
        
        Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÛŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙÙˆÙ‚ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.
        Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ Ùˆ Ù„Ø­Ù† Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ Ù…Ø´Ø§ÙˆØ±Ø§Ù†Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯.
        Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:
        1. Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡
        2. Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø±ÙˆØ³
        3. ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÙˆØ³ Ù…ÙˆØ±Ø¯ Ù†ÙØ±Øª
        4. Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ù…Ø¤Ø«Ø±
        
        Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ ØªØ§ Ù¾Ø§Ø³Ø® Ø¬Ø°Ø§Ø¨â€ŒØªØ± Ø´ÙˆØ¯. ğŸ“šâœï¸â°ğŸ“
        """
        
        # Ù¾Ø± Ú©Ø±Ø¯Ù† Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±
        prompt = ChatPromptTemplate.from_template(template)
        
        prompt_values = {
            "name": user_profile.get("name", "Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²"),
            "grade": user_profile.get("grade", "Ù†Ø§Ù…Ø´Ø®Øµ"),
            "exam_date": user_profile.get("exam_date", "Ù†Ø§Ù…Ø´Ø®Øµ"),
            "favorite_subjects": ", ".join(user_profile.get("favorite_subjects", [])),
            "disliked_subjects": ", ".join(user_profile.get("disliked_subjects", [])),
            "desired_major": user_profile.get("desired_major", "Ù†Ø§Ù…Ø´Ø®Øµ"),
            "message": message
        }
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ø§Ø² LLM
        messages = prompt.format_messages(**prompt_values)
        response = llm.invoke(messages)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø§Ø³Ø® Ø¯Ø± state
        state["response"] = response.content
        return state
    
    return generate_study_plan

def performance_analysis_node(llm):
    """Ú¯Ø±Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢Ø²Ù…ÙˆÙ†"""
    def analyze_performance(state):
        user_profile = state["user_profile"]
        exam_results = state.get("exam_results", {})
        
        # Ø³Ø§Ø®Øª Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ø±Ø§ÛŒ LLM
        template = """
        Ø´Ù…Ø§ Ù…Ø´Ø§ÙˆØ± ØªØ­ØµÛŒÙ„ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ² Ù‡Ø³ØªÛŒØ¯ Ùˆ Ø¨Ø§ÛŒØ¯ Ù†ØªØ§ÛŒØ¬ Ø¢Ø²Ù…ÙˆÙ† Ø§Ùˆ Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯.
        
        Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²:
        - Ù†Ø§Ù…: {name}
        - Ù¾Ø§ÛŒÙ‡ ØªØ­ØµÛŒÙ„ÛŒ: {grade}
        - ØªØ§Ø±ÛŒØ® Ú©Ù†Ú©ÙˆØ±: {exam_date}
        - Ø¯Ø±ÙˆØ³ Ù…ÙˆØ±Ø¯ Ø¹Ù„Ø§Ù‚Ù‡: {favorite_subjects}
        - Ø¯Ø±ÙˆØ³ Ù…ÙˆØ±Ø¯ Ù†ÙØ±Øª: {disliked_subjects}
        - Ø±Ø´ØªÙ‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±: {desired_major}
        
        Ù†ØªØ§ÛŒØ¬ Ø¢Ø²Ù…ÙˆÙ†:
        {exam_results}
        
        Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ÛŒ Ø§Ø² Ù†ØªØ§ÛŒØ¬ Ø¢Ø²Ù…ÙˆÙ† Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙÙˆÙ‚ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.
        Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ Ùˆ Ù„Ø­Ù† Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ Ù…Ø´Ø§ÙˆØ±Ø§Ù†Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯.
        ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:
        1. Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ùˆ Ø¶Ø¹Ù
        2. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Ø¯Ø±ÙˆØ³ Ù…Ø®ØªÙ„Ù
        3. ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÙˆØ³ Ø¶Ø¹ÛŒÙâ€ŒØªØ±
        4. Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØª
        
        Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ ØªØ§ Ù¾Ø§Ø³Ø® Ø¬Ø°Ø§Ø¨â€ŒØªØ± Ø´ÙˆØ¯. ğŸ“ŠğŸ“ˆğŸ“‰ğŸ“š
        """
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ù†ØªØ§ÛŒØ¬ Ø¢Ø²Ù…ÙˆÙ†
        exam_results_text = "\n".join([f"- {subject}: {score}" for subject, score in exam_results.items()])
        
        # Ù¾Ø± Ú©Ø±Ø¯Ù† Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø± Ùˆ Ù†ØªØ§ÛŒØ¬ Ø¢Ø²Ù…ÙˆÙ†
        prompt = ChatPromptTemplate.from_template(template)
        
        prompt_values = {
            "name": user_profile.get("name", "Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²"),
            "grade": user_profile.get("grade", "Ù†Ø§Ù…Ø´Ø®Øµ"),
            "exam_date": user_profile.get("exam_date", "Ù†Ø§Ù…Ø´Ø®Øµ"),
            "favorite_subjects": ", ".join(user_profile.get("favorite_subjects", [])),
            "disliked_subjects": ", ".join(user_profile.get("disliked_subjects", [])),
            "desired_major": user_profile.get("desired_major", "Ù†Ø§Ù…Ø´Ø®Øµ"),
            "exam_results": exam_results_text
        }
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ø§Ø² LLM
        messages = prompt.format_messages(**prompt_values)
        response = llm.invoke(messages)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø§Ø³Ø® Ø¯Ø± state
        state["response"] = response.content
        return state
    
    return analyze_performance

def general_chat_node(llm):
    """Ú¯Ø±Ù‡ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ"""
    def generate_general_response(state):
        user_profile = state["user_profile"]
        message = state["messages"][-1].content if state["messages"] else ""
        memory = state["memory"]
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø­Ø§ÙØ¸Ù‡ Ú©ÙˆØªØ§Ù‡ Ù…Ø¯Øª Ø¨Ù‡ ØµÙˆØ±Øª ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡
        from graph.memory import get_formatted_memory
        memory_context = get_formatted_memory(memory)
        
        # ØªØ´Ø®ÛŒØµ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù¾ÛŒØ§Ù…
        relevant_info = get_relevant_profile_info(message, user_profile)
        
        # ØªØ¹ÛŒÛŒÙ† Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø® Ø¨Ø± Ø§Ø³Ø§Ø³ Ø·ÙˆÙ„ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        is_short_message = len(message.split()) < 10
        length_instruction = "Ù¾Ø§Ø³Ø® Ø±Ø§ Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…Ø®ØªØµØ± Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ (Ø­Ø¯Ø§Ú©Ø«Ø± 2-3 Ø¬Ù…Ù„Ù‡)." if is_short_message else ""
        
        # Ø³Ø§Ø®Øª Ù¾Ø±Ø§Ù…Ù¾Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ LLM
        template = """
        Ø´Ù…Ø§ Ù…Ø´Ø§ÙˆØ± ØªØ­ØµÛŒÙ„ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ² Ù‡Ø³ØªÛŒØ¯ Ùˆ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ Ø³Ø¤Ø§Ù„ ÛŒØ§ Ù¾ÛŒØ§Ù… Ø§Ùˆ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯.
        
        Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²:
        - Ù†Ø§Ù…: {name}
        
        {relevant_info_text}
        
        ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ù‚Ø¨Ù„ÛŒ:
        {memory_context}
        
        Ù¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²: {message}
        
        Ù…Ù‡Ù…: Ø¨Ù‡ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ù‚Ø¨Ù„ÛŒ ØªÙˆØ¬Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ Ø§Ø² ØªÚ©Ø±Ø§Ø± Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯ÙˆÛŒÛŒ ÛŒØ§ Ø³Ù„Ø§Ù… Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.
        Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ Ùˆ Ù„Ø­Ù† Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯.
        ØªÙ†Ù‡Ø§ Ø¨Ù‡ Ù¾ÛŒØ§Ù… ÙØ¹Ù„ÛŒ Ú©Ø§Ø±Ø¨Ø± Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯ Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª Ø·Ø¨ÛŒØ¹ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡ Ø±Ø§ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ù‡ÛŒØ¯.
        {length_instruction}
        """
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ù†Ø§Ø³Ø¨
        relevant_info_text = ""
        for key, value in relevant_info.items():
            if key == "name":
                continue  # Ù†Ø§Ù… Ø¯Ø± ÙØ±Ù…Øª Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
            if key == "favorite_subjects" or key == "disliked_subjects":
                if isinstance(value, list):
                    value = ", ".join(value)
            key_name = {
                "grade": "Ù¾Ø§ÛŒÙ‡ ØªØ­ØµÛŒÙ„ÛŒ",
                "exam_date": "ØªØ§Ø±ÛŒØ® Ú©Ù†Ú©ÙˆØ±",
                "favorite_subjects": "Ø¯Ø±ÙˆØ³ Ù…ÙˆØ±Ø¯ Ø¹Ù„Ø§Ù‚Ù‡",
                "disliked_subjects": "Ø¯Ø±ÙˆØ³ Ù…ÙˆØ±Ø¯ Ù†ÙØ±Øª",
                "desired_major": "Ø±Ø´ØªÙ‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±"
            }.get(key, key)
            relevant_info_text += f"- {key_name}: {value}\n"
            
        # Ù¾Ø± Ú©Ø±Ø¯Ù† Ù¾Ø±Ø§Ù…Ù¾Øª
        prompt = ChatPromptTemplate.from_template(template)
        
        prompt_values = {
            "name": user_profile.get("name", "Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²"),
            "message": message,
            "relevant_info_text": relevant_info_text,
            "memory_context": memory_context,
            "length_instruction": length_instruction
        }
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ø§Ø² LLM
        messages = prompt.format_messages(**prompt_values)
        response = llm.invoke(messages)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø§Ø³Ø® Ø¯Ø± state
        state["response"] = response.content
        return state
    
    return generate_general_response

def get_relevant_profile_info(message, user_profile):
    """ØªØ´Ø®ÛŒØµ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±"""
    relevant_info = {"name": user_profile.get("name", "Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²")}
    
    # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¨Ø®Ø´ Ù¾Ø±ÙˆÙØ§ÛŒÙ„
    keywords = {
        "grade": ["Ù¾Ø§ÛŒÙ‡", "Ú©Ù„Ø§Ø³", "Ø³Ø§Ù„ ØªØ­ØµÛŒÙ„ÛŒ", "Ø¯Ù‡Ù…", "ÛŒØ§Ø²Ø¯Ù‡Ù…", "Ø¯ÙˆØ§Ø²Ø¯Ù‡Ù…"],
        "exam_date": ["Ú©Ù†Ú©ÙˆØ±", "Ø¢Ø²Ù…ÙˆÙ†", "ØªØ§Ø±ÛŒØ®", "Ø²Ù…Ø§Ù†", "Ø§Ù…ØªØ­Ø§Ù†"],
        "favorite_subjects": ["Ø¹Ù„Ø§Ù‚Ù‡", "Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù…", "Ø¯Ø±Ø³ Ù…ÙˆØ±Ø¯ Ø¹Ù„Ø§Ù‚Ù‡", "Ø¹Ù„Ø§Ù‚Ù…Ù†Ø¯Ù…"],
        "disliked_subjects": ["Ù…ØªÙ†ÙØ±", "Ø¨Ø¯Ù… Ù…ÛŒØ§Ø¯", "Ø³Ø®Øª", "Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±Ù…", "Ø¶Ø¹ÛŒÙ"],
        "desired_major": ["Ø±Ø´ØªÙ‡", "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡", "Ù‡Ø¯Ù", "Ø¢ÛŒÙ†Ø¯Ù‡", "Ø§Ø¯Ø§Ù…Ù‡ ØªØ­ØµÛŒÙ„", "ØªØ­ØµÛŒÙ„"]
    }
    
    # ØªØ¨Ø¯ÛŒÙ„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú© Ø¨Ø±Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ø¢Ø³Ø§Ù†â€ŒØªØ±
    message_lower = message.lower()
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± Ù¾ÛŒØ§Ù…
    for info_key, key_list in keywords.items():
        for keyword in key_list:
            if keyword in message_lower:
                relevant_info[info_key] = user_profile.get(info_key, "Ù†Ø§Ù…Ø´Ø®Øµ")
                break
    
    return relevant_info